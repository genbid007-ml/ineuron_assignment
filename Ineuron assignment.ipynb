{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f91f3c",
   "metadata": {},
   "source": [
    "## Python Screening Assignment\n",
    "\n",
    "\n",
    "   1. Create a function in python to read the text file and replace specific content of the file.\n",
    "\n",
    "        File name: example.txt\n",
    "        \n",
    "        Origin file content: This is a placement assignment\n",
    "        \n",
    "        Replace string:  Placement should be replaced by screening.\n",
    "        \n",
    "        Replaced file content: This is a screening assignment\n",
    "\n",
    "2. Demonstrate use of abstract class, multiple inheritance and decorator in python using examples.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560825c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "  \n",
    "def python_fileupdate(search_text='placement',replace_text='screening', file_name='example.txt'):\n",
    "\n",
    "    try:\n",
    "        with open(file_name,'r+') as f:\n",
    "            file = f.read() # Reading the file data \n",
    "            file= file.lower()\n",
    "            file = re.sub(search_text, replace_text, file)\n",
    "            f.seek(0)# seek the pointer to beginning\n",
    "            f.write(file)\n",
    "            f.truncate()\n",
    "    except IOError:\n",
    "        print(\"Error: Could not find file or read data\")\n",
    "    else: \n",
    "        print(\"Content updated  successfully\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6947fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content updated  successfully\n"
     ]
    }
   ],
   "source": [
    "python_fileupdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732afc4a",
   "metadata": {},
   "source": [
    "## Using Abstract class with MLModel\n",
    "\n",
    "In this code I am creating a MLModel abstract class with inputSchema (to define data take input for prediction) output schema (what output get for display or API to digest as JSON or other format) and a predict method.\n",
    "\n",
    "Them we create a simple train method to train the model with iris dataset and then we create a child class ***IrisSVCModel(MLModel)*** and implement all three abstract method to load the trained model and done prediction with defined input/output schema. Then we create a simple predict method to return output schema for API digestion. Rest of the code is self-explanatory.\n",
    "\n",
    "Note: I have went thro different blog posts to comiple this code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d850f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class MLModel(ABC):\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def input_schema(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def output_schema(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, data):\n",
    "        self.input_schema.validate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d83a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "def train():\n",
    "    #load data from IRIS data set\n",
    "    iris = datasets.load_iris()\n",
    "    #create a model\n",
    "    svm_model = svm.SVC(gamma=0.001, C=100.0)\n",
    "    #fit the model with IRIS Dataset\n",
    "    svm_model.fit(iris.data[:-1], iris.target[:-1])\n",
    "\n",
    "    #create a pickle file in local directory\n",
    "    file = open(\"svc_model.pickle\", 'wb')\n",
    "    #dump the file\n",
    "    pickle.dump(svm_model,file)\n",
    "    print(\"Training completed and {} is saved\".format(file.name))\n",
    "    #close the file to access by predict method\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c171a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed and svc_model.pickle is saved\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "416f94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from schema import Schema, Or\n",
    "from numpy import array\n",
    "\n",
    "class IrisSVCModel(MLModel):\n",
    "    \"\"\" A demonstration of how to use  \"\"\"\n",
    "    input_schema = Schema({'sepal_length': float,\n",
    "                           'sepal_width': float,\n",
    "                           'petal_length': float,\n",
    "                           'petal_width': float})\n",
    "\n",
    "    # the output of the model will be one of three strings\n",
    "    output_schema = Schema({'species': Or(\"setosa\", \"versicolor\", \"virginica\")})\n",
    "\n",
    "    def __init__(self):\n",
    "        file = open(\"svc_model.pickle\", 'rb')\n",
    "        self._svm_model = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    def predict(self, data):\n",
    "        # calling the super method to validate against the input_schema\n",
    "        super().predict(data=data)\n",
    "\n",
    "        # converting the incoming dictionary into a numpy array that can be accepted by the  model\n",
    "        X = array([data[\"sepal_length\"], data[\"sepal_width\"], data[\"petal_length\"], data[\"petal_width\"]]).reshape(1, -1)\n",
    "\n",
    "        # making the prediction and extracting the result from the array\n",
    "        y_hat = int(self._svm_model.predict(X)[0])\n",
    "\n",
    "        #converting the prediction into a string that will match the output schema of the model\n",
    "        # this list will map the output of the scikit-learn model to the output string expected by the schema\n",
    "        targets = ['setosa', 'versicolor', 'virginica']\n",
    "        species = targets[y_hat]\n",
    "\n",
    "        return {\"species\": species}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ab0a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'sepal_length': 1.0,\n",
    "        'sepal_width': 5.0,\n",
    "        'petal_length': 1.0,\n",
    "        'petal_width': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf744334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species': 'setosa'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= IrisSVCModel()\n",
    "pred.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bdb4f",
   "metadata": {},
   "source": [
    "# Multiple inheritence\n",
    "\n",
    "A class can be derived from more than one base class in Python, similar to C++. This is called multiple inheritance. In multiple inheritance, the features of all the base classes are inherited into the derived class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0a9f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Tokenizer class who splits the sentence into tokens\n",
    "class Tokenizer:\n",
    "    def __init__(self, text):\n",
    "        print('Tokenizer Class')\n",
    "        self.tokens = text.split()\n",
    "\n",
    "        \n",
    "# WordCounter count no of tokens by inherit the Tokenizer class\n",
    "class WordCounter(Tokenizer):\n",
    "    def __init__(self, text):\n",
    "        print('Start WordCounter class')\n",
    "        super().__init__(text)\n",
    "        self.word_count = len(self.tokens)\n",
    "\n",
    "# Vocabulary class Find unique words in text\n",
    "class Vocabulary(Tokenizer):\n",
    "    def __init__(self, text):\n",
    "        print('Start Vocabulary class')\n",
    "        super().__init__(text)\n",
    "        self.vocab = set(self.tokens)\n",
    "\n",
    "#TextDescribes class inherit both Word count and Vocabulary class which shows multiple inheritence     \n",
    "class TextDescriber(WordCounter, Vocabulary):\n",
    "    def __init__(self, text):\n",
    "        print('Start TextDescriber class')\n",
    "        super().__init__(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5988f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start TextDescriber class\n",
      "Start WordCounter class\n",
      "Start Vocabulary class\n",
      "Tokenizer Class\n"
     ]
    }
   ],
   "source": [
    "td = TextDescriber('Hi I am student of Ineuron, I am learning Data Science, I am from Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2db33f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN:  ['Hi', 'I', 'am', 'student', 'of', 'Ineuron,', 'I', 'am', 'learning', 'Data', 'Science,', 'I', 'am', 'from', 'Delhi']\n",
      "VOCAB:  {'learning', 'of', 'Science,', 'Data', 'student', 'from', 'Ineuron,', 'am', 'Delhi', 'Hi', 'I'}\n",
      "Word Length:  15\n"
     ]
    }
   ],
   "source": [
    "print(\"TOKEN: \", td.tokens)\n",
    "print(\"VOCAB: \", td.vocab)\n",
    "print(\"Word Length: \", td.word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6df26",
   "metadata": {},
   "source": [
    "# Decorator \n",
    "A decorator in Python is a function that takes another function as an argument and extends its behavior without explicitly modifying it. For example from Krish Sir vedio, in the following code we can create main_welcome function which can take a function as arguments and decorate it with sub_welcome_class, we can use the same logic for logging in Data science model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb725937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decorators\n",
    "def main_welcome(func):\n",
    "    def sub_welcome_class():\n",
    "        print(\"Welcome To Krish Naik Youtube Channel\")\n",
    "        func()\n",
    "        print(\"Please subscribe Krish channel\")\n",
    "    return sub_welcome_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e2fe5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome To Krish Naik Youtube Channel\n",
      "This is Krish youtube channel\n",
      "Please subscribe Krish channel\n"
     ]
    }
   ],
   "source": [
    "@main_welcome\n",
    "def channel_name():\n",
    "    print(\"This is Krish youtube channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f7add",
   "metadata": {},
   "source": [
    "By using the same logic we can create a ***log_computation*** function which takes function as argument and define a wrapper function which can be used to log the info from which function it is called and result in the log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "297e0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def log_computation(func):\n",
    "    def wrapper(*args):\n",
    "        logging.basicConfig(filename='Logger.log',level=logging.INFO)\n",
    "        logging.info(\"Info message being logged from function: \" + str(func))\n",
    "        res = func(*args)\n",
    "        logging.info(\"The result from function call is: \"+ str(res))\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ab83fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_computation\n",
    "def sum_up(n, m):\n",
    "    return n + m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e9c787a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_up(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a90f49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_computation\n",
    "def substract(n, m):\n",
    "    return n - m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7a505c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substract(10,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
